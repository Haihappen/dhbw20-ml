{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Encoder\n",
    "\n",
    "Der Autoencoder versucht, eine Funktion $h_{W,b}(x) \\approx x$ zu lernen. Mit anderen Worten, er versucht, eine Annäherung an die Identitätsfunktion zu lernen, um $\\hat{x}$ auszugeben, die x ähnlich ist. Die Identitätsfunktion scheint eine besonders triviale Funktion zu sein, die zu lernen ist; aber indem wir dem Netzwerk Beschränkungen auferlegen, wie z.B. durch Begrenzung der Anzahl hidden layers, können wir eine interessante Struktur über die Daten entdecken. \n",
    "\n",
    "Als konkretes Beispiel nehmen wir an, die Eingaben x sind die Pixel-Intensitätswerte aus einem 28×28-Bild (784 Pixel), also n=784, und es gibt $s_2$=128 verborgene Einheiten in der Ebene $L_2$. Beachten Sie, dass wir auch $y \\in \\mathbb{R}^{784}$ haben. \n",
    "\n",
    "Da es nur 128 versteckte Einheiten gibt, ist das Netzwerk gezwungen, eine \"komprimierte\" Darstellung der Eingabe zu lernen. D.h., wenn es nur den Vektor der Aktivierungen der verborgenen Einheiten $a^{(2)} \\in \\mathbb{R}^{128}$ erhält, muss es versuchen, die 784-Pixel-Eingabe x zu \"rekonstruieren\". \n",
    "\n",
    "Wenn die Eingabe völlig zufällig wäre, wäre diese Komprimierungsaufgabe sehr schwierig. Wenn die Daten jedoch strukturiert sind, z.B. wenn einige der Eingabemerkmale korreliert sind, dann ist dieser Algorithmus in der Lage, einige dieser Korrelationen zu entdecken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST Dataset\n",
    "\n",
    "`Fashion-MNIST` ist ein Datensatz von Zalandos Artikelbildern - bestehend aus einem Trainingssatz mit 60.000 Beispielen und einem Testsatz mit 10.000 Beispielen. \n",
    "\n",
    "Jedes Beispiel ist ein Graustufenbild im Format 28x28, das mit einem Label aus 10 Klassen verbunden ist. Fashion-MNIST ist ein direkter Drop-in-Ersatz für den ursprünglichen MNIST-Datensatz von handgeschriebenen Ziffern. Der Datensatz hat die gleiche Bildgröße und die gleiche Struktur von Trainings- und Test-Splits.\n",
    "\n",
    "Jedes Bild trägt einen der folgenden Label:\n",
    "\n",
    "Label | Description\n",
    "--- | ---\n",
    "0|T-shirt/top\n",
    "1|Trouser\n",
    "2|Pullover\n",
    "3|Dress\n",
    "4|Coat\n",
    "5|Sandal\n",
    "6|Shirt\n",
    "7|Sneaker\n",
    "8|Bag\n",
    "9|Ankle boot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset parameters.\n",
    "num_features = 784 # data features (img shape: 28*28).\n",
    "\n",
    "# Training parameters.\n",
    "learning_rate = 0.01\n",
    "training_steps = 20000\n",
    "batch_size = 256\n",
    "display_step = 1000\n",
    "\n",
    "# Network Parameters\n",
    "num_hidden_1 = 128 # 1st layer num features.\n",
    "num_hidden_2 = 64 # 2nd layer num features (the latent dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten vorbereiten\n",
    "\n",
    "Jedes Bild wird konvertiert zu float32, normalisiert auf das Intervall [0, 1] and ausgestreckt auf ein 1-dimensionales Array von 784 Features (28*28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to float32.\n",
    "x_train, x_test = x_train.astype(np.float32), x_test.astype(np.float32)\n",
    "# Flatten images to 1-D vector of 784 features (28*28).\n",
    "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
    "# Normalize images value from [0, 255] to [0, 1].\n",
    "x_train, x_test = x_train / 255., x_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein TensorFlow **`tf.data.Dataset`** dient der Verwaltung von potentiell gewaltigen Datenmengen.\n",
    "\n",
    "Die `tf.data.Dataset` API unterstützt das Schreiben sprechender und effizienter Eingabe-Pipelines. Die Dataset-Verwendung folgt einem gemeinsamen Muster:\n",
    "\n",
    "- Erstellen Sie einen Quelldatensatz aus Ihren Eingabedaten.\n",
    "- Wenden Sie Dataset-Transformationen zur Vorverarbeitung der Daten an.\n",
    "- Iterieren Sie über das Dataset und verarbeiten Sie die Elemente.\n",
    "\n",
    "Die Iteration erfolgt in einem Streaming-Verfahren, so dass der vollständige Datensatz nicht in den Speicher passen muss.\n",
    "\n",
    "**Einige Methoden:**\n",
    "- `repeat(count)`: Wiederholt diesen Datensatz, so dass jeder Originalwert `count`-mal gesehen wird. Default: unendlich\n",
    "- `shuffle(buffer_size)`: Mischt die Elemente dieses Datensatzes nach dem Zufallsprinzip um.\n",
    "\n",
    "    Dieser Datensatz füllt einen Puffer mit buffer_size-Elementen, nimmt dann nach dem Zufallsprinzip Stichproben von Elementen aus diesem Puffer und ersetzt die ausgewählten Elemente durch neue Elemente. Für ein perfektes Mischen ist eine Puffergröße erforderlich, die größer oder gleich der vollen Größe des Datensatzes ist.\n",
    "\n",
    "    Wenn Ihr Datensatz beispielsweise 10.000 Elemente enthält, buffer_size jedoch auf 1.000 eingestellt ist, wählt die Zufallsmischung zunächst ein Zufallselement aus nur den ersten 1.000 Elementen im Puffer aus. Sobald ein Element ausgewählt ist, wird sein Platz im Puffer durch das nächste (d. h. das 1.001-st.) Element ersetzt, wobei der Puffer mit 1.000 Elementen beibehalten wird.\n",
    "\n",
    "- `batch(batch_size)`: Sammelt aufeinander folgende Elemente dieses Datensatzes zu Batch-Stapeln.\n",
    "- `prefetch(buffer_size)`: Erstellt ein Dataset, das Elemente aus diesem Dataset vorzeitig abruft.\n",
    "\n",
    "    Die meisten Dataset-Eingabe-Pipelines sollten mit einem Aufruf von `prefetch` enden. Auf diese Weise können spätere Elemente vorbereitet werden, während das aktuelle Element verarbeitet wird. Dies verbessert oft die Latenzzeit und den Durchsatz auf Kosten der Verwendung von zusätzlichem Speicher zum Speichern vorgeladener Elemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(60000).batch(batch_size).prefetch(1)\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_data = test_data.repeat().batch(batch_size).prefetch(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D.h. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store layers weight & bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A random value generator to initialize weights.\n",
    "random_normal = tf.initializers.RandomNormal()\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(random_normal([num_features, num_hidden_1])),\n",
    "    'encoder_h2': tf.Variable(random_normal([num_hidden_1, num_hidden_2])),\n",
    "    'decoder_h1': tf.Variable(random_normal([num_hidden_2, num_hidden_1])),\n",
    "    'decoder_h2': tf.Variable(random_normal([num_hidden_1, num_features])),\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(random_normal([num_hidden_1])),\n",
    "    'encoder_b2': tf.Variable(random_normal([num_hidden_2])),\n",
    "    'decoder_b1': tf.Variable(random_normal([num_hidden_1])),\n",
    "    'decoder_b2': tf.Variable(random_normal([num_features])),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation.\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
    "    \n",
    "    # Encoder Hidden layer with sigmoid activation.\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
    "    \n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x):\n",
    "    # Decoder Hidden layer with sigmoid activation.\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n",
    "    \n",
    "    # Decoder Hidden layer with sigmoid activation.\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n",
    "    \n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean square loss between original images and reconstructed ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square(reconstructed, original):\n",
    "    return tf.reduce_mean(tf.pow(original - reconstructed, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(x):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        reconstructed_image = decoder(encoder(x))\n",
    "        loss = mean_square(reconstructed_image, x)\n",
    "\n",
    "    # Variables to update, i.e. trainable variables.\n",
    "    trainable_variables = {**weights, **biases}.values()\n",
    "    \n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainiere das Modell\n",
    "\n",
    "`take(count)` holt sich die nächsten `count` Batch-Elemente aus dem Dataset-Strom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (batch_x, _) in enumerate(train_data.take(training_steps + 1)):\n",
    "    \n",
    "    # Run the optimization.\n",
    "    loss = run_optimization(batch_x)\n",
    "    \n",
    "    if step % display_step == 0:\n",
    "        print(\"step: %i, loss: %f\" % (step, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Encode and decode images from test set and visualize their reconstruction.\n",
    "n = 4\n",
    "\n",
    "canvas_orig = np.empty((28 * n, 28 * n))\n",
    "canvas_recon = np.empty((28 * n, 28 * n))\n",
    "\n",
    "for i, (batch_x, _) in enumerate(test_data.take(n)):\n",
    "    # Encode and decode the digit image.\n",
    "    reconstructed_images = decoder(encoder(batch_x))\n",
    "\n",
    "    # Display original images.\n",
    "    for j in range(n):\n",
    "        # Draw the generated digits.\n",
    "        img = batch_x[j].numpy().reshape([28, 28])\n",
    "        canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = img\n",
    "    \n",
    "    # Display reconstructed images.\n",
    "    for j in range(n):\n",
    "        # Draw the generated digits.\n",
    "        reconstr_img = reconstructed_images[j].numpy().reshape([28, 28])\n",
    "        canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = reconstr_img\n",
    "\n",
    "print(\"Original Images\")     \n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Reconstructed Images\")\n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
