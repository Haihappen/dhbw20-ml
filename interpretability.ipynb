{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Datensatz\n",
    "\n",
    "Die Spalten haben folgende Bedeutung:\n",
    "\n",
    "Variable\t|Definition\t|Key\n",
    ":---|:---|---\n",
    "Survival\t|Survival - Label\t|0 = No, 1 = Yes\n",
    "Pclass\t|Ticket class\t|1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "Sex\t|Sex\t| male, female\n",
    "Age\t|Age in years|\t\n",
    "SibSp\t|# of siblings / spouses aboard the Titanic\t|\n",
    "Parch\t| # of parents / children aboard the Titanic\t|\n",
    "Ticket\t|Ticket number\t|\n",
    "Fare\t|Passenger fare\t|\n",
    "Cabin\t|Cabin number\t|\n",
    "Embarked\t|Port of Embarkation\t|C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "Name|Name des Passagiers |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/titanic/train.csv')\n",
    "test = pd.read_csv('./data/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenaufbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Cabin'], axis=1, inplace=True)\n",
    "train.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = train.groupby(\"Pclass\")[\"Age\"]\n",
    "print(age_group.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Altersmedian unterscheided sich zwischen den Klassen signifikant, also setzen wir diesen für die fehlenden Werte ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.Age.isnull(), 'Age'] = train.groupby(\"Pclass\").Age.transform('median')\n",
    "print(train[\"Age\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['PassengerId', 'Name', 'Ticket', 'Fare'], axis = 1, inplace = True)\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna('S')\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_onehot = pd.get_dummies(train, drop_first=True)\n",
    "train_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training vorbereiten\n",
    "\n",
    "`train` enthält ja sowohl unsere Features als auch das Label `Survived`. Dies teilen wir jetzt auf in X und y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_onehot['Survived']\n",
    "X = train_onehot.drop('Survived', axis=1)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schließlich splitten wir unsere Daten noch in ein Training- und ein Test-Set im Verhältnis 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistische Regression\n",
    "\n",
    "Trainiere das Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... und bewerte das Ergebnis ...\n",
    "\n",
    "**Confusion Matrix:** Die Confusion-Matrix $C$ ist definiert durch: $C_{i,j}$ ist die Anzahl der Beobachtungen der wahren Gruppe $i$, die als zur Gruppe $j$ vorhergesagt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(\"\\t'false'\\t'true'\")\n",
    "print(\"false\\t  {}\\t  {}\".format(tn, fp))\n",
    "print(\"true\\t  {}\\t  {}\".format(fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kennzahlen zur Bewertung\n",
    "\n",
    "**Precision** ist das Verhältnis $\\frac{tp}{tp + fp}$, wobei $tp$ die Anzahl der echten positiven und $fp$ die Anzahl der falschen positiven Werte ist. Intuitiv ist Precision die Fähigkeit des Klassifikators, eine negative Probe nicht als positiv zu kennzeichnen.\n",
    "\n",
    "**Recall** ist das Verhältnis $\\frac{tp}{tp + fn}$, wobei $fn$ die Anzahl der falschen Negativen ist. Intuitiv ist Recall die Fähigkeit des Klassifikators, alle positiven Proben zu finden.\n",
    "\n",
    "Der **F-Beta-Score** kann als ein gewichteter harmonischer Mittelwert von Precision und Recall interpretiert werden, wobei ein F-Beta-Score seinen besten Wert bei 1 und den schlechtesten Wert bei 0 erreicht.\n",
    "\n",
    "$f1=2\\times\\frac{Precision \\times Recall}{Precision + Recall}$\n",
    "\n",
    "Der F-Beta-Score gewichtet um den Faktor Beta Recall mehr als die Precision. Beta == 1,0 bedeutet, dass Recall und Precision gleich wichtig sind.\n",
    "\n",
    "**Support** ist die jeweilige Anzahl der Vorkommnisse der wahren Labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, target_names=['Nicht überlebt', 'Überlebt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation des Modells\n",
    "\n",
    "Schauen wir uns Intercept und Koeffizienten an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Intercept/Bias: {}'.format(model.intercept_))\n",
    "\n",
    "coef_dict = sorted(list(zip(X.columns.tolist(), model.coef_.ravel())), key=lambda tup: tup[1])\n",
    "for tup in coef_dict:\n",
    "    print(tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Geschlecht ist mit Abstand der am stärksten eingehende Faktor, gefolgt von der Klasse.\n",
    "\n",
    "Da wir die Features nicht skaliert haben, stimmt die Reihenfolge bzgl SibSp, Parch und insbesondere Age so allerdings nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.h. Age geht eigentlich mit einem fast 30-fachen Gewicht gegenüber den 0/1-Features ein und steht damit eher an dritter Stelle.\n",
    "\n",
    "SibSp und Parch könnte man vielleicht als Familie zusammenfassen (Familiengröße = 1 + SibSp + Parch) und dann trainieren, oder eventuell die Familiengröße auch One-Hot Encoden.\n",
    "\n",
    "Das geht dann in Richtung \"Feature Engineering\". Ein interessanter Artikel dazu im Kontext des Titanic Datasets \n",
    "ist [hier](https://medium.com/i-like-big-data-and-i-cannot-lie/how-i-scored-in-the-top-9-of-kaggles-titanic-machine-learning-challenge-243b5f45c8e9) zu finden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(train_onehot, \n",
    "                                                   feature_names=['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S'], \n",
    "                                                   class_names=[0, 1], \n",
    "                                                   categorical_features=[0, 4, 5, 6], \n",
    "                                                   verbose=True, \n",
    "                                                   mode='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
